{{^global.generation.isCallisto}}
---
AWSTemplateFormatVersion: '2010-09-09'
Description: k8s default nodes

Resources:
  KubeIamRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: "nodes.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
          - Effect: Allow
            Principal:
              Service:
                - ec2.amazonaws.com
            Action:
              - sts:AssumeRole
      Path: "/"
      ManagedPolicyArns:
        - arn:aws:iam::aws:policy/service-role/AmazonEC2RoleforSSM
      Policies:
        - PolicyName: "node.k8s.{{global.clusterName}}"
          PolicyDocument:
            Version: '2012-10-17'
            Statement:
              - Effect: Allow
                Action:
                  - ec2:*
                  - ecr:GetAuthorizationToken
                  - ecr:BatchCheckLayerAvailability
                  - ecr:GetDownloadUrlForLayer
                  - ecr:GetRepositoryPolicy
                  - ecr:DescribeRepositories
                  - ecr:ListImages
                  - ecr:BatchGetImage
                  - autoscaling:DescribeAutoScalingGroups
                  - autoscaling:UpdateAutoScalingGroup
                  - autoscaling:SetInstanceHealth
                  - autoscaling:DescribeAutoScalingInstances
                Resource: "*"
              - Effect: Allow
                Action:
                  - ssm:GetParameter
                  - ssm:GetParameters
                  - ssm:GetParametersByPath
                Resource:
                  - !Sub arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/ops/jupiter/clusters/{{global.clusterId}}/node
                  - !Sub arn:aws:ssm:${AWS::Region}:${AWS::AccountId}:parameter/ops/jupiter/clusters/{{global.clusterId}}/node/*
              - Effect: Allow
                Action:
                  - logs:Describe*
                  - logs:CreateLogStream
                  - logs:PutLogEvents
                Resource: "*"
              - Effect: Allow
                Action:
                  - sts:AssumeRole
                Resource: arn:aws:iam::*:role/k8s/*

  KubeIamInstanceProfile:
    Type: AWS::IAM::InstanceProfile
    Properties:
      Path: "/"
      Roles:
        - !Ref KubeIamRole

  KubeLaunchTemplateDefaultA:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        IamInstanceProfile:
          Name: !Ref KubeIamInstanceProfile
        ImageId: {{global.amiId}}
        Monitoring:
          Enabled: false
        InstanceType: {{ index $config.defaultNodes.instanceTypes 0}}
        KeyName: "{{global.sshKeyName}}"
        SecurityGroupIds:
          - Fn::ImportValue:
              "{{global.clusterName}}-KubeNodeSecurityGroup"
          - Fn::ImportValue:
              "BastionAccessSecurityGroup-{{global.vpcId}}"
        BlockDeviceMappings:
          - DeviceName: "/dev/xvda"
            Ebs:
              VolumeSize: {{defaultNodes.volumeSize}}
              VolumeType: "gp2"
              DeleteOnTermination: true
        UserData:
          Fn::Base64:
            !Sub |
              #!/bin/bash

              set -e

              exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1

              function cleanup {
                last_exit=$?
                status="Unhealthy"

                if [[ "$last_exit" == 0 ]]; then
                  status="Healthy"
                fi

                /opt/aws/bin/cfn-signal --exit-code $last_exit --region ${AWS::Region} --resource KubeInstanceAutoscalingGroupDefaultA --stack ${AWS::StackName} || true

                aws autoscaling set-instance-health \
                  --region ${AWS::Region} \
                  --no-should-respect-grace-period \
                  --instance-id "$(curl http://169.254.169.254/latest/meta-data/instance-id)" \
                  --health-status "$status"
              }

              trap cleanup EXIT

              private_ip=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
              asg_index=$(curl http://169.254.169.254/latest/meta-data/ami-launch-index)

              AMI_ID={{global.amiId}}
              INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
              ASG_INSTANCE=$(aws autoscaling describe-auto-scaling-instances --region ap-southeast-2 --instance-ids "${!INSTANCE_ID}")
              ASG_NAME=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].AutoScalingGroupName')
              ASG_LT_Name=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateName')
              ASG_LT_Id=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateId')
              ASG_LT_Version=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.Version')
              ASG_LT_MD5=$(echo "${!ASG_LT_Id}-${!ASG_LT_Version}" | md5sum | cut -d ' ' -f 1)

              NODE_LABELS=myob.com/node-pool={{defaultNodes.nodePoolName}}
              NODE_LABELS=${!NODE_LABELS},node-pool.myob.com/{{defaultNodes.nodePoolName}}=true
              NODE_LABELS=${!NODE_LABELS},node.kubernetes.io/role="node"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/amiID="${!AMI_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/instanceID="${!INSTANCE_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/asgName="${!ASG_NAME:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateName="${!ASG_LT_Name:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateId="${!ASG_LT_Id:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateVersion="${!ASG_LT_Version:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateMd5="${!ASG_LT_MD5:0:63}"

              cat << EOF > /opt/kubernetes/env
              CLUSTER_NAME={{global.clusterName}}
              CLUSTER_DOMAIN={{global.clusterBaseDomain}}
              CLUSTER_ROLE=node
              AWS_REGION=${AWS::Region}
              PRIVATE_IP=$private_ip
              ASG_INDEX=$asg_index
              KUBELET_EXTRA_ARGS="{{ if has $config.defaultNodes "taints"}}--register-with-taints={{ join $config.defaultNodes.taints ","}} {{ end}}--node-labels=${!NODE_LABELS}"
              EOF

              env $(cat /opt/kubernetes/env | xargs -d '\n') /usr/bin/kubeadm-join

              systemctl enable node-drain
              systemctl start node-drain

  KubeLaunchTemplateDefaultB:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        IamInstanceProfile:
          Name: !Ref KubeIamInstanceProfile
        ImageId: {{global.amiId}}
        Monitoring:
          Enabled: false
        InstanceType: {{ index $config.defaultNodes.instanceTypes 0}}
        KeyName: "{{global.sshKeyName}}"
        SecurityGroupIds:
          - Fn::ImportValue:
              "{{global.clusterName}}-KubeNodeSecurityGroup"
          - Fn::ImportValue:
              "BastionAccessSecurityGroup-{{global.vpcId}}"
        BlockDeviceMappings:
          - DeviceName: "/dev/xvda"
            Ebs:
              VolumeSize: {{defaultNodes.volumeSize}}
              VolumeType: "gp2"
              DeleteOnTermination: true
        UserData:
          Fn::Base64:
            !Sub |
              #!/bin/bash

              set -e

              exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1

              function cleanup {
                last_exit=$?
                status="Unhealthy"

                if [[ "$last_exit" == 0 ]]; then
                  status="Healthy"
                fi

                /opt/aws/bin/cfn-signal --exit-code $last_exit --region ${AWS::Region} --resource KubeInstanceAutoscalingGroupDefaultB --stack ${AWS::StackName} || true

                aws autoscaling set-instance-health \
                  --region ${AWS::Region} \
                  --no-should-respect-grace-period \
                  --instance-id "$(curl http://169.254.169.254/latest/meta-data/instance-id)" \
                  --health-status "$status"
              }

              trap cleanup EXIT

              private_ip=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
              asg_index=$(curl http://169.254.169.254/latest/meta-data/ami-launch-index)

              AMI_ID={{global.amiId}}
              INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
              ASG_INSTANCE=$(aws autoscaling describe-auto-scaling-instances --region ap-southeast-2 --instance-ids "${!INSTANCE_ID}")
              ASG_NAME=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].AutoScalingGroupName')
              ASG_LT_Name=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateName')
              ASG_LT_Id=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateId')
              ASG_LT_Version=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.Version')
              ASG_LT_MD5=$(echo "${!ASG_LT_Id}-${!ASG_LT_Version}" | md5sum | cut -d ' ' -f 1)

              NODE_LABELS=myob.com/node-pool={{defaultNodes.nodePoolName}}
              NODE_LABELS=${!NODE_LABELS},node-pool.myob.com/{{defaultNodes.nodePoolName}}=true
              NODE_LABELS=${!NODE_LABELS},node.kubernetes.io/role="node"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/amiID="${!AMI_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/instanceID="${!INSTANCE_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/asgName="${!ASG_NAME:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateName="${!ASG_LT_Name:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateId="${!ASG_LT_Id:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateVersion="${!ASG_LT_Version:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateMd5="${!ASG_LT_MD5:0:63}"

              cat << EOF > /opt/kubernetes/env
              CLUSTER_NAME={{global.clusterName}}
              CLUSTER_DOMAIN={{global.clusterBaseDomain}}
              CLUSTER_ROLE=node
              AWS_REGION=${AWS::Region}
              PRIVATE_IP=$private_ip
              ASG_INDEX=$asg_index
              KUBELET_EXTRA_ARGS="{{ if has $config.defaultNodes "taints"}}--register-with-taints={{ join $config.defaultNodes.taints ","}} {{ end}}--node-labels=${!NODE_LABELS}"
              EOF

              env $(cat /opt/kubernetes/env | xargs -d '\n') /usr/bin/kubeadm-join

              systemctl enable node-drain
              systemctl start node-drain

  KubeLaunchTemplateDefaultC:
    Type: AWS::EC2::LaunchTemplate
    Properties:
      LaunchTemplateData:
        IamInstanceProfile:
          Name: !Ref KubeIamInstanceProfile
        ImageId: {{global.amiId}}
        Monitoring:
          Enabled: false
        InstanceType: {{ index $config.defaultNodes.instanceTypes 0}}
        KeyName: "{{global.sshKeyName}}"
        SecurityGroupIds:
          - Fn::ImportValue:
              "{{global.clusterName}}-KubeNodeSecurityGroup"
          - Fn::ImportValue:
              "BastionAccessSecurityGroup-{{global.vpcId}}"
        BlockDeviceMappings:
          - DeviceName: "/dev/xvda"
            Ebs:
              VolumeSize: {{defaultNodes.volumeSize}}
              VolumeType: "gp2"
              DeleteOnTermination: true
        UserData:
          Fn::Base64:
            !Sub |
              #!/bin/bash

              set -e

              exec > >(tee /var/log/user-data.log|logger -t user-data -s 2>/dev/console) 2>&1

              function cleanup {
                last_exit=$?
                status="Unhealthy"

                if [[ "$last_exit" == 0 ]]; then
                  status="Healthy"
                fi

                /opt/aws/bin/cfn-signal --exit-code $last_exit --region ${AWS::Region} --resource KubeInstanceAutoscalingGroupDefaultC --stack ${AWS::StackName} || true

                aws autoscaling set-instance-health \
                  --region ${AWS::Region} \
                  --no-should-respect-grace-period \
                  --instance-id "$(curl http://169.254.169.254/latest/meta-data/instance-id)" \
                  --health-status "$status"
              }

              trap cleanup EXIT

              private_ip=$(curl http://169.254.169.254/latest/meta-data/local-ipv4)
              asg_index=$(curl http://169.254.169.254/latest/meta-data/ami-launch-index)

              AMI_ID={{global.amiId}}
              INSTANCE_ID=$(curl -s http://169.254.169.254/latest/meta-data/instance-id)
              ASG_INSTANCE=$(aws autoscaling describe-auto-scaling-instances --region ap-southeast-2 --instance-ids "${!INSTANCE_ID}")
              ASG_NAME=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].AutoScalingGroupName')
              ASG_LT_Name=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateName')
              ASG_LT_Id=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.LaunchTemplateId')
              ASG_LT_Version=$(echo "${!ASG_INSTANCE}" | jq -Mrc '.AutoScalingInstances[0].LaunchTemplate.Version')
              ASG_LT_MD5=$(echo "${!ASG_LT_Id}-${!ASG_LT_Version}" | md5sum | cut -d ' ' -f 1)

              NODE_LABELS=myob.com/node-pool={{defaultNodes.nodePoolName}}
              NODE_LABELS=${!NODE_LABELS},node-pool.myob.com/{{defaultNodes.nodePoolName}}=true
              NODE_LABELS=${!NODE_LABELS},node.kubernetes.io/role="node"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/amiID="${!AMI_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/instanceID="${!INSTANCE_ID:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/asgName="${!ASG_NAME:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateName="${!ASG_LT_Name:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateId="${!ASG_LT_Id:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateVersion="${!ASG_LT_Version:0:63}"
              NODE_LABELS=${!NODE_LABELS},aws.myob.com/launchTemplateMd5="${!ASG_LT_MD5:0:63}"

              cat << EOF > /opt/kubernetes/env
              CLUSTER_NAME={{global.clusterName}}
              CLUSTER_DOMAIN={{global.clusterBaseDomain}}
              CLUSTER_ROLE=node
              AWS_REGION=${AWS::Region}
              PRIVATE_IP=$private_ip
              ASG_INDEX=$asg_index
              KUBELET_EXTRA_ARGS="{{ if has $config.defaultNodes "taints"}}--register-with-taints={{ join $config.defaultNodes.taints ","}} {{ end}}--node-labels=${!NODE_LABELS}"
              EOF

              env $(cat /opt/kubernetes/env | xargs -d '\n') /usr/bin/kubeadm-join

              systemctl enable node-drain
              systemctl start node-drain

  KubeInstanceAutoscalingGroupDefaultA:
    Type: "AWS::AutoScaling::AutoScalingGroup"
    CreationPolicy:
      AutoScalingCreationPolicy:
        MinSuccessfulInstancesPercent: {{global.minSuccessfulInstancesPercent}}
      ResourceSignal:
        Count: {{defaultNodes.minInstancesPerASG}}
        Timeout: {{global.asgPauseTime}}
    Properties:
      AutoScalingGroupName: "nodes-a.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
      MinSize: {{defaultNodes.minInstancesPerASG}}
      MaxSize: {{defaultNodes.maxInstancesPerASG}}
      MixedInstancesPolicy:
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref KubeLaunchTemplateDefaultA
            Version: !GetAtt KubeLaunchTemplateDefaultA.LatestVersionNumber
          Overrides:
          {{- range $config.defaultNodes.instanceTypes}}
            - InstanceType: {{.}}
          {{- end}}
      Tags:
        - Key: Name
          Value: "nodes-a.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: KubernetesCluster
          Value: "{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/enabled
          Value: "yes"
          PropagateAtLaunch: true
        - Key: myob.com/node-pool
          Value: "{{defaultNodes.nodePoolName}}"
          PropagateAtLaunch: true
        - Key: "kubernetes.io/cluster/{{global.clusterId}}"
          Value: "true"
          PropagateAtLaunch: true
        - Key: k8s.io/role/node
          Value: "1"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/autoscaling
          Value: "1"
          PropagateAtLaunch: true
        - Key: "k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/{{global.clusterName}}"
          Value: "1"
          PropagateAtLaunch: true
      TerminationPolicies:
        - OldestInstance
      VPCZoneIdentifier:
        - "{{ index $config.global.privateSubnetIds 0}}"

  KubeInstanceAutoscalingGroupDefaultB:
    Type: "AWS::AutoScaling::AutoScalingGroup"
    CreationPolicy:
      AutoScalingCreationPolicy:
        MinSuccessfulInstancesPercent: {{global.minSuccessfulInstancesPercent}}
      ResourceSignal:
        Count: {{defaultNodes.minInstancesPerASG}}
        Timeout: {{global.asgPauseTime}}
    Properties:
      AutoScalingGroupName: "nodes-b.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
      MinSize: {{defaultNodes.minInstancesPerASG}}
      MaxSize: {{defaultNodes.maxInstancesPerASG}}
      MixedInstancesPolicy:
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref KubeLaunchTemplateDefaultB
            Version: !GetAtt KubeLaunchTemplateDefaultB.LatestVersionNumber
          Overrides:
          {{- range $config.defaultNodes.instanceTypes}}
            - InstanceType: {{.}}
          {{- end}}
      Tags:
        - Key: Name
          Value: "nodes-b.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: KubernetesCluster
          Value: "{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/enabled
          Value: "yes"
          PropagateAtLaunch: true
        - Key: myob.com/node-pool
          Value: "{{defaultNodes.nodePoolName}}"
          PropagateAtLaunch: true
        - Key: "kubernetes.io/cluster/{{global.clusterId}}"
          Value: "true"
          PropagateAtLaunch: true
        - Key: k8s.io/role/node
          Value: "true"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/autoscaling
          Value: "1"
          PropagateAtLaunch: true
        - Key: "k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/{{global.clusterName}}"
          Value: "1"
          PropagateAtLaunch: true
      TerminationPolicies:
        - OldestInstance
      VPCZoneIdentifier:
        - "{{ index $config.global.privateSubnetIds 1}}"

  KubeInstanceAutoscalingGroupDefaultC:
    Type: "AWS::AutoScaling::AutoScalingGroup"
    CreationPolicy:
      AutoScalingCreationPolicy:
        MinSuccessfulInstancesPercent: {{global.minSuccessfulInstancesPercent}}
      ResourceSignal:
        Count: {{defaultNodes.minInstancesPerASG}}
        Timeout: {{global.asgPauseTime}}
    Properties:
      AutoScalingGroupName: "nodes-c.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
      MinSize: {{defaultNodes.minInstancesPerASG}}
      MaxSize: {{defaultNodes.maxInstancesPerASG}}
      MixedInstancesPolicy:
        LaunchTemplate:
          LaunchTemplateSpecification:
            LaunchTemplateId: !Ref KubeLaunchTemplateDefaultC
            Version: !GetAtt KubeLaunchTemplateDefaultC.LatestVersionNumber
          Overrides:
          {{- range $config.defaultNodes.instanceTypes}}
            - InstanceType: {{.}}
          {{- end}}
      Tags:
        - Key: Name
          Value: "nodes-c.{{defaultNodes.nodePoolName}}.{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: KubernetesCluster
          Value: "{{global.clusterId}}"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/enabled
          Value: "yes"
          PropagateAtLaunch: true
        - Key: myob.com/node-pool
          Value: "{{defaultNodes.nodePoolName}}"
          PropagateAtLaunch: true
        - Key: "kubernetes.io/cluster/{{global.clusterId}}"
          Value: "true"
          PropagateAtLaunch: true
        - Key: k8s.io/role/node
          Value: "true"
          PropagateAtLaunch: true
        - Key: k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/autoscaling
          Value: "1"
          PropagateAtLaunch: true
        - Key: "k8s.io/cluster-autoscaler/node-template/label/k8s.myob.com/{{global.clusterName}}"
          Value: "1"
          PropagateAtLaunch: true
      TerminationPolicies:
        - OldestInstance
      VPCZoneIdentifier:
        - "{{ index $config.global.privateSubnetIds 2}}"

Outputs:
  NodeRole:
    Value: !Ref KubeIamRole
    Export:
      Name: "{{global.clusterName}}-{{defaultNodes.nodePoolName}}-NodeRole"
  AsgA:
    Value: !Ref KubeInstanceAutoscalingGroupDefaultA
    Export:
      Name: "{{global.clusterName}}-{{defaultNodes.nodePoolName}}-NodeAutoscalingGroupA"
  AsgB:
    Value: !Ref KubeInstanceAutoscalingGroupDefaultB
    Export:
      Name: "{{global.clusterName}}-{{defaultNodes.nodePoolName}}-NodeAutoscalingGroupB"
  AsgC:
    Value: !Ref KubeInstanceAutoscalingGroupDefaultC
    Export:
      Name: "{{global.clusterName}}-{{defaultNodes.nodePoolName}}-NodeAutoscalingGroupC"
{{/global.generation.isCallisto}}
